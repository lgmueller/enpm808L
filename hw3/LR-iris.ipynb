{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "## Lillian Mueller and Regina Hong \n",
    "Investigating linear regression for Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (\n",
    "    linear_model, \n",
    "    preprocessing, \n",
    "    model_selection, \n",
    "    metrics, \n",
    "    tree)\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in the iris dataset from sklearn\n",
    "iris_data = load_iris()\n",
    "\n",
    "# turning dataset into dataframe format for easier reading\n",
    "df_iris = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "      <th>class_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "    class  class_level  \n",
       "0  setosa            0  \n",
       "1  setosa            0  \n",
       "2  setosa            0  \n",
       "3  setosa            0  \n",
       "4  setosa            0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding the target as a class column and renaming numbers to class names\n",
    "# 0 = setosa, 1 = versicolor, 2 = virginica\n",
    "\n",
    "df_iris['class'] = iris_data.target.tolist()\n",
    "df_iris['class'].replace({0: 'setosa', 1: 'versicolor', 2: 'virginica'},\n",
    "                inplace=True)\n",
    "\n",
    "#Create a new column for the target (to be ready for processing)\n",
    "label_obj = preprocessing.LabelEncoder()\n",
    "df_iris['class_level'] = label_obj.fit_transform(df_iris['class'])\n",
    "\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0:  9.25103654908234\n",
      "B1:  -0.43987188985753245\n",
      "B2:  0.791757898112843\n",
      "B3:  -2.253980881949735\n",
      "B4:  -0.9750798513425657\n"
     ]
    }
   ],
   "source": [
    "# Creating Train and Test datasets\n",
    "predictors, target = iris_data.data, iris_data.target\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    predictors, \n",
    "    target, \n",
    "    test_size = 0.33)\n",
    "\n",
    "# create logistic regression to classify iris\n",
    "logR = linear_model.LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "# find coefficients \n",
    "B0 = logR.intercept_[0]\n",
    "B1 = logR.coef_[0][0]\n",
    "B2 = logR.coef_[0][1]\n",
    "B3 = logR.coef_[0][2]\n",
    "B4 = logR.coef_[0][3]\n",
    "print('B0: ', B0)\n",
    "print('B1: ', B1)\n",
    "print('B2: ', B2)\n",
    "print('B3: ', B3)\n",
    "print('B4: ', B4)\n",
    "\n",
    "#mu = -B0/B1\n",
    "#s = 1/B1\n",
    "#print('mu: ', mu)\n",
    "#print('s: ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98, 0.94, 0.9053030303030303]\n"
     ]
    }
   ],
   "source": [
    "# Test model with testing dataset and find accuracy \n",
    "logR_pred = logR.predict(x_test)\n",
    "accuracy = {\n",
    "    'LogReg' : [\n",
    "        metrics.accuracy_score(y_train, logR.predict(x_train)), \n",
    "        metrics.accuracy_score(y_test, logR_pred),\n",
    "        metrics.r2_score(y_test, logR_pred)\n",
    "    ]\n",
    "}\n",
    "print(accuracy['LogReg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.92, 0.8737373737373737]\n"
     ]
    }
   ],
   "source": [
    "# create decision tree model using same training and test datasets \n",
    "dTree = tree.DecisionTreeClassifier(criterion='gini').fit(x_train, y_train)\n",
    "\n",
    "# Test model with testing dataset and find accuracy \n",
    "dtree_pred = dTree.predict(x_test)\n",
    "accuracy['DTree'] = [\n",
    "        metrics.accuracy_score(y_train, dTree.predict(x_train)), \n",
    "        metrics.accuracy_score(y_test, dtree_pred),\n",
    "        metrics.r2_score(y_test, dtree_pred)\n",
    "    ]\n",
    "\n",
    "print(accuracy['DTree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Data Accuracy</th>\n",
       "      <th>Test Data Accuracy</th>\n",
       "      <th>r2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.905303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.873737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Train Data Accuracy  Test Data Accuracy  r2 Score\n",
       "LogReg                 0.98                0.94  0.905303\n",
       "DTree                  1.00                0.92  0.873737"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the accuracy of each model \n",
    "pd.DataFrame.from_dict(\n",
    "    accuracy,\n",
    "    orient='index', \n",
    "    columns=[\n",
    "        'Train Data Accuracy', \n",
    "        'Test Data Accuracy', \n",
    "        'r2 Score'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dt(criterion, X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    dTree = tree.DecisionTreeClassifier(criterion=criterion).fit(x_train, y_train)\n",
    "    dtree_pred = dTree.predict(x_test)\n",
    "    \n",
    "    return [ \n",
    "        metrics.accuracy_score(y_train, dTree.predict(x_train)), \n",
    "        metrics.accuracy_score(y_test, dtree_pred),\n",
    "        metrics.r2_score(y_test, dtree_pred)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max_iter parameter to 1000 so that model woulod converge\n",
    "def run_LR(penalty, X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    logR = linear_model.LogisticRegression(penalty=penalty,\n",
    "                                          max_iter=1000).fit(x_train, y_train)\n",
    "    logR_pred = logR.predict(x_test)\n",
    "    \n",
    "    # find coefficients \n",
    "    B0 = logR.intercept_[0]\n",
    "    B1 = logR.coef_[0][0]    \n",
    "    \n",
    "    mu = -B0/B1\n",
    "    s = 1/B1\n",
    "\n",
    "    return [\n",
    "        metrics.accuracy_score(y_train, logR.predict(x_train)), \n",
    "        metrics.accuracy_score(y_test, logR_pred),\n",
    "        metrics.r2_score(y_test, logR_pred)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dt model with gini inpurity 1000 times\n",
      "       Train Data Accuracy  Test Data Accuracy     r2 Score\n",
      "count               1000.0         1000.000000  1000.000000\n",
      "mean                   1.0            0.930180     0.889804\n",
      "std                    0.0            0.015447     0.024380\n",
      "min                    1.0            0.920000     0.873737\n",
      "25%                    1.0            0.920000     0.873737\n",
      "50%                    1.0            0.920000     0.873737\n",
      "75%                    1.0            0.940000     0.905303\n",
      "max                    1.0            0.960000     0.936869\n"
     ]
    }
   ],
   "source": [
    "print('Run dt model with gini inpurity 1000 times')\n",
    "dt_scores = []\n",
    "for i in range(1000):\n",
    "    dt_scores.append(run_dt('gini', x_train, x_test, y_train, y_test))\n",
    "\n",
    "dt_score_df = pd.DataFrame(dt_scores, columns=['Train Data Accuracy', 'Test Data Accuracy', 'r2 Score'])\n",
    "print(dt_score_df.describe().round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run LR model with L2 penalty 1000 times\n",
      "       Train Data Accuracy  Test Data Accuracy     r2 Score\n",
      "count              1000.00             1000.00  1000.000000\n",
      "mean                  0.98                0.94     0.905303\n",
      "std                   0.00                0.00     0.000000\n",
      "min                   0.98                0.94     0.905303\n",
      "25%                   0.98                0.94     0.905303\n",
      "50%                   0.98                0.94     0.905303\n",
      "75%                   0.98                0.94     0.905303\n",
      "max                   0.98                0.94     0.905303\n"
     ]
    }
   ],
   "source": [
    "print('Run LR model with L2 penalty 1000 times')\n",
    "LR_L2_scores = []\n",
    "for i in range(1000):\n",
    "    LR_L2_scores.append(run_LR('l2', x_train, x_test, y_train, y_test))\n",
    "\n",
    "LR_L2_score_df = pd.DataFrame(LR_L2_scores, columns=['Train Data Accuracy', 'Test Data Accuracy', 'r2 Score'])\n",
    "print(LR_L2_score_df.describe().round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run LR model with No penalty 1000 times\n",
      "       Train Data Accuracy  Test Data Accuracy     r2 Score\n",
      "count               1000.0             1000.00  1000.000000\n",
      "mean                   1.0                0.96     0.936869\n",
      "std                    0.0                0.00     0.000000\n",
      "min                    1.0                0.96     0.936869\n",
      "25%                    1.0                0.96     0.936869\n",
      "50%                    1.0                0.96     0.936869\n",
      "75%                    1.0                0.96     0.936869\n",
      "max                    1.0                0.96     0.936869\n"
     ]
    }
   ],
   "source": [
    "print('Run LR model with No penalty 1000 times')\n",
    "LR_N_scores = []\n",
    "for i in range(1000):\n",
    "    LR_N_scores.append(run_LR(None, x_train, x_test, y_train, y_test))\n",
    "\n",
    "LR_N_score_df = pd.DataFrame(LR_N_scores, columns=['Train Data Accuracy', 'Test Data Accuracy', 'r2 Score'])\n",
    "print(LR_N_score_df.describe().round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob of setosa (0)</th>\n",
       "      <th>Prob of versicolor (1)</th>\n",
       "      <th>Prob of virginica (2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.106</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prob of setosa (0)  Prob of versicolor (1)  Prob of virginica (2)\n",
       "30                0.965                   0.035                  0.000\n",
       "71                0.030                   0.922                  0.048\n",
       "73                0.006                   0.790                  0.203\n",
       "81                0.072                   0.906                  0.022\n",
       "143               0.000                   0.027                  0.973\n",
       "133               0.001                   0.440                  0.559\n",
       "83                0.001                   0.313                  0.686\n",
       "129               0.000                   0.189                  0.811\n",
       "42                0.988                   0.012                  0.000\n",
       "79                0.106                   0.885                  0.009"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create ranking of results of logistic regression model \n",
    "probRanks = pd.DataFrame(\n",
    "    logR.predict_proba(predictors), \n",
    "    columns=[\n",
    "        'Prob of setosa (0)', \n",
    "        'Prob of versicolor (1)', \n",
    "        'Prob of virginica (2)'\n",
    "    ]\n",
    ")\n",
    "probRanks.sample(10).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob of setosa (0)</th>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.012343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob of versicolor (1)</th>\n",
       "      <td>0.076790</td>\n",
       "      <td>0.966225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob of virginica (2)</th>\n",
       "      <td>0.923044</td>\n",
       "      <td>0.021431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0         1\n",
       "sepal length (cm)       5.800000  6.000000\n",
       "sepal width (cm)        2.800000  2.200000\n",
       "petal length (cm)       5.100000  4.000000\n",
       "petal width (cm)        2.400000  1.000000\n",
       "Prediction              2.000000  1.000000\n",
       "Prob of setosa (0)      0.000166  0.012343\n",
       "Prob of versicolor (1)  0.076790  0.966225\n",
       "Prob of virginica (2)   0.923044  0.021431"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rank two new records \n",
    "records = [\n",
    "    [5.8,2.8,5.1,2.4],\n",
    "    [6.0,2.2,4.0,1.0]\n",
    "]\n",
    "newRecords = pd.DataFrame(\n",
    "    records, \n",
    "    columns=[\n",
    "        'sepal length (cm)',\n",
    "        'sepal width (cm)',\n",
    "        'petal length (cm)',\n",
    "        'petal width (cm)'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# making prediction with model \n",
    "newRecords['Prediction'] = logR.predict(records)\n",
    "\n",
    "# adding rankings to dataframe\n",
    "rankProbs = pd.DataFrame(\n",
    "    logR.predict_proba(records),\n",
    "    columns=[\n",
    "        'Prob of setosa (0)', \n",
    "        'Prob of versicolor (1)', \n",
    "        'Prob of virginica (2)'\n",
    "        ]\n",
    "    )\n",
    "newRecords[rankProbs.columns] = rankProbs\n",
    "\n",
    "newRecords.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
