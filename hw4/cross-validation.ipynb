{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "## Lillian Mueller and Regina Hong \n",
    "Comparing models using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (\n",
    "    linear_model, \n",
    "    preprocessing,\n",
    "    model_selection,\n",
    "    metrics, \n",
    "    tree)\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "      <th>class_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "47                 4.6               3.2                1.4               0.2   \n",
       "43                 5.0               3.5                1.6               0.6   \n",
       "64                 5.6               2.9                3.6               1.3   \n",
       "115                6.4               3.2                5.3               2.3   \n",
       "\n",
       "          class  class_level  \n",
       "47       setosa            0  \n",
       "43       setosa            0  \n",
       "64   versicolor            1  \n",
       "115   virginica            2  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in the iris dataset from sklearn\n",
    "iris_data = load_iris()\n",
    "\n",
    "# turning dataset into dataframe format for easier reading\n",
    "df_iris = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "\n",
    "# adding the target as a class column and renaming numbers to class names\n",
    "# 0 = setosa, 1 = versicolor, 2 = virginica\n",
    "\n",
    "df_iris['class'] = iris_data.target.tolist()\n",
    "df_iris['class'].replace({0: 'setosa', 1: 'versicolor', 2: 'virginica'},\n",
    "                inplace=True)\n",
    "\n",
    "#Create a new column for the target (to be ready for processing)\n",
    "label_obj = preprocessing.LabelEncoder()\n",
    "df_iris['class_level'] = label_obj.fit_transform(df_iris['class'])\n",
    "\n",
    "print(\"Full Dataset:\")\n",
    "df_iris.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation of Logistic Regression without Penalty\n",
      "          0\n",
      "0  1.000000\n",
      "1  1.000000\n",
      "2  0.933333\n",
      "3  0.933333\n",
      "4  1.000000\n"
     ]
    }
   ],
   "source": [
    "# cross validation of logistic model without penality\n",
    "# using without penality highest accuracy as shown in report 3\n",
    "predictors, target = iris_data.data, iris_data.target\n",
    "\n",
    "logR_cross_val = model_selection.cross_val_score(\n",
    "    linear_model.LogisticRegression(penalty=None), \n",
    "    predictors, \n",
    "    target, \n",
    "    cv = None,  # default -> 5-fold cross validation\n",
    "    scoring='accuracy'\n",
    ")\n",
    "print(\"Cross Validation of Logistic Regression without Penalty\")\n",
    "logR = pd.DataFrame(logR_cross_val)\n",
    "print(logR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation using Decision Tree with Entropy\n",
      "          0\n",
      "0  0.966667\n",
      "1  0.966667\n",
      "2  0.900000\n",
      "3  0.933333\n",
      "4  1.000000\n"
     ]
    }
   ],
   "source": [
    "# cross validation of decision tree with entropy\n",
    "# using entropy method showed highest accuracy as shown in report 2\n",
    "dtree_cross_val = model_selection.cross_val_score(\n",
    "    tree.DecisionTreeClassifier(criterion='entropy'), \n",
    "    predictors, \n",
    "    target, \n",
    "    cv = None,  # default -> 5-fold cross validation\n",
    "    scoring='accuracy'\n",
    ")\n",
    "print(\"Cross Validation using Decision Tree with Entropy\")\n",
    "dtree = pd.DataFrame(dtree_cross_val)\n",
    "print(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stardard Dev.</th>\n",
       "      <td>0.036515</td>\n",
       "      <td>0.038006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Logistic Regression  Decision Tree\n",
       "Mean                      0.973333       0.953333\n",
       "Stardard Dev.             0.036515       0.038006"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison of score means and standard deviation \n",
    "# create table comparing average and std of multiple dataframes\n",
    "def comparison_table(dfs, columns):\n",
    "    meanScores = pd.concat(\n",
    "        [df.mean() for df in dfs], \n",
    "        axis=1)\n",
    "    meanScores.columns = [col for col in columns]\n",
    "\n",
    "    stdScores = pd.concat(\n",
    "        [df.std() for df in dfs], \n",
    "        axis=1)\n",
    "    stdScores.columns = [col for col in columns]\n",
    "\n",
    "    comparison = pd.concat([meanScores, stdScores], ignore_index=True)\n",
    "    comparison.index = ['Mean', 'Stardard Dev.']\n",
    "    return comparison\n",
    "\n",
    "comparison_table([logR, dtree], ['Logistic Regression', 'Decision Tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to perform manual cross validation\n",
    "def perform_manual_cross_validation(dataset, feature_cols, target_col, model, numFolds):\n",
    "    accuracy = [] # collect accuracy of each fold\n",
    "    fulldataset = dataset.copy() # keep copy of full dataset\n",
    "\n",
    "    for i in range(numFolds):\n",
    "        # get separate group for traning fold\n",
    "        # since dataframe is getting smaller, must adjust the fraction of entries taken each time\n",
    "        train_fold = dataset.sample(frac=(1/(numFolds-i)))\n",
    "\n",
    "        # get remaining dataset to use a test folds\n",
    "        test_folds = fulldataset.drop(train_fold.index)\n",
    "\n",
    "        # fit model \n",
    "        mod = model.fit(train_fold[feature_cols], train_fold[target_col])\n",
    "        \n",
    "        # get accuracy of model\n",
    "        accuracy.append(\n",
    "            metrics.accuracy_score(\n",
    "                test_folds[target_col], \n",
    "                mod.predict(test_folds[feature_cols]))\n",
    "        )\n",
    "\n",
    "        # keep track of unused data entries \n",
    "        dataset.drop(train_fold.index, inplace=True)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation of Logistic Regression without Penalty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.958333\n",
       "1    0.958333\n",
       "2    0.841667\n",
       "3    0.891667\n",
       "4    0.966667\n",
       "Name: Logistic Regression, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cross Validation of Logistic Regression without Penalty\")\n",
    "logR_accuracy = perform_manual_cross_validation(\n",
    "    df_iris.copy(), \n",
    "    ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], \n",
    "    'class_level', \n",
    "    linear_model.LogisticRegression(penalty=None), \n",
    "    5\n",
    "    )\n",
    "accuracy = pd.DataFrame()\n",
    "accuracy['Logistic Regression'] = logR_accuracy\n",
    "accuracy['Logistic Regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation using Decision Tree with Entropy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.933333\n",
       "1    0.941667\n",
       "2    0.950000\n",
       "3    0.950000\n",
       "4    0.950000\n",
       "Name: Decision Tree, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cross Validation using Decision Tree with Entropy\")\n",
    "dtree_accuracy = perform_manual_cross_validation(\n",
    "    df_iris.copy(), \n",
    "    ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], \n",
    "    'class_level', \n",
    "    tree.DecisionTreeClassifier(criterion='entropy'), \n",
    "    5\n",
    "    )\n",
    "accuracy['Decision Tree'] = dtree_accuracy\n",
    "accuracy['Decision Tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average\n",
      "Logistic Regression    0.956667\n",
      "Decision Tree          0.898333\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Logistic Regression    0.010865\n",
      "Decision Tree          0.072265\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Average')\n",
    "print(accuracy.mean())\n",
    "print('Standard Deviation')\n",
    "print(accuracy.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
